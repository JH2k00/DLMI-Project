{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JadHa\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Users\\JadHa\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are now using cuda.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torch.nn as nn\n",
    "from kvasir_capsule_dataset import get_dataloader\n",
    "from trainer import train_kc_model\n",
    "import gc\n",
    "from custom_transforms import GaussianBlur, RandomChoiceExtended\n",
    "import os\n",
    "\n",
    "with_gpu = torch.cuda.is_available()\n",
    "\n",
    "if with_gpu:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print('We are now using %s.' % device)\n",
    "\n",
    "train_path = r\"C:\\Users\\JadHa\\Desktop\\Uni\\DLMB\\DLMI-Project\\kvasir-capsule-labeled-images\\dataset_train.csv\"\n",
    "val_path = r\"C:\\Users\\JadHa\\Desktop\\Uni\\DLMB\\DLMI-Project\\kvasir-capsule-labeled-images\\dataset_test.csv\"\n",
    "dataset_path = r\"C:\\Users\\JadHa\\Desktop\\Uni\\DLMB\\DLMI-Project\\kvasir-capsule-labeled-images\\labelled_images\"\n",
    "\n",
    "resnet = resnet18().to(device) # weights=ResNet18_Weights.IMAGENET1K_V1\n",
    "\n",
    "resnet.fc = nn.Linear(512, 2).to(device)\n",
    "\n",
    "transforms_list = [transforms.Compose([transforms.RandomResizedCrop(size=96),transforms.Resize(size=[336, 336])]),\n",
    "                   transforms.RandomRotation(degrees=360),\n",
    "                   GaussianBlur(kernel_size=3),\n",
    "                   transforms.ColorJitter(0.1, 0.1, 0.003, 0.003)]\n",
    "\n",
    "transform = RandomChoiceExtended(transforms_list, min_transforms=0, max_transforms=3)\n",
    "\n",
    "train_loader = get_dataloader(csv_path=train_path, dataset_path=dataset_path, batch_size=128, shuffle=True, transforms=transform, drop_data_till_balanced=False)\n",
    "val_loader = get_dataloader(csv_path=val_path, dataset_path=dataset_path, batch_size=128, shuffle=True)\n",
    "\n",
    "optimizer = optim.AdamW(params=resnet.parameters(), lr=3e-4)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([1, 20]).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = train_loader.dataset[0][0]\n",
    "image_aug = transform(image)\n",
    "print(\"Original shape : %s, Augmented shape : %s\"%(image.shape, image_aug.shape))\n",
    "plt.imshow(torch.cat([image, image_aug], dim=2).permute(1,2,0).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet18().to(device) # weights=ResNet18_Weights.IMAGENET1K_V1\n",
    "resnet.fc = nn.Linear(512, 2).to(device)\n",
    "optimizer = optim.AdamW(params=resnet.parameters(), lr=3e-4)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpoint = torch.load(os.path.join(\"saved_models\", \"vqvae_vctk_amp_clip1_2.pt\"))\n",
    "resnet.load_state_dict(chkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(chkpoint[\"optimizer\"])\n",
    "scaler.load_state_dict(chkpoint[\"scaler\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "train_kc_model(resnet, optimizer, criterion, train_loader, val_loader, scaler, model_name=\"Resnet_AMP\", epochs=40, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
